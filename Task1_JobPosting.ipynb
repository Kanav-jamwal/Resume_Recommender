{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "#### Date: 02/09/2018\n",
    "\n",
    "Environment: Python 3.6.5 and Anaconda 5.2 (64-bit)\n",
    "\n",
    "Libraries used:\n",
    "* re - for getting the words and the number (Getting the desried string).  \n",
    "* json library for creating the json file.\n",
    "\n",
    "#### USING REGEX TO FETCH THE RESPECTIVE DATA FOR EACH JOB:\n",
    "\n",
    "* WE SPLIT THE GIVEN STRING ON -----------------------\n",
    "* APPLY REGEX TO FETCH THE REQUIRED DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "Python Programming can be used to process text data for the requirements in various textual data analysis. A very important area of application of such text processing ability of python is for NLP (Natural Language Processing). NLP is used in search engines, newspaper feed analysis and more recently for voice -based applications like Siri and Alexa. Python's Natural Language Toolkit (NLTK) is a group of libraries that can be used for creating such Text Processing systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open(\"29554209.dat\",\"r\") as file: \n",
    "    list_job = file.read()\n",
    "ids=[]\n",
    "description=[]\n",
    "title=[]\n",
    "about_company=[]\n",
    "start_date=[]\n",
    "location=[]\n",
    "qualification=[]\n",
    "dead_line=[]\n",
    "responsibilty=[]\n",
    "procedure=[]\n",
    "salary=[]\n",
    "\n",
    "for each in list_job.split('------------------------------'):  \n",
    "    ids.append(re.findall(r'(?:ID)\\s?:(.*)',each,re.IGNORECASE))  \n",
    "    description.append(re.findall(r'(\\w*?_?\\s?(?:DESC)\\w*?:)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    location.append(re.findall(r'((?:LOC)\\w*:|\\w*?_?(?:LOC)\\w?:)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    title.append(re.findall(r'((?:JOB)?\\s?(?:TITLE)\\w*:|(?:JOB)?_(?:T|TTL):)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    about_company.append(re.findall(r'((?:ABOUT)_?\\s?\\w*:|(?:COMP)?\\w*?_?(?:INFO):)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    start_date.append(re.findall(r'(^\\w*[_\\s]?(?:start|date|da)\\s?\\w*\\s?):(\\s\\d\\d\\s\\w{1,6}\\s\\d\\d\\d\\d.*?)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    qualification.append(re.findall(r'(?:QUAL)\\w*:|(?:REQ)\\w*?_??\\s?(QUAL)\\w*:(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    dead_line.append(re.findall(r'(\\w*?_?D(?:EAD|L)_?\\s?\\w*?:)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    responsibilty.append(re.findall(r'((?:JOB)?_?\\s?(?:RESP)\\w*:)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    procedure.append(re.findall(r'(\\w*?_?(?:PROC)\\w*:)(.*?\\s?)(?=^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:)',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n",
    "    salary.append(re.findall(r'((?:JOB)?_?(?:SAL)\\w*?:|(?:REMU)\\w*:)(\\s?.*?)(.*?\\s?)(?=(?:^\\s*?\\n?_?\\w*_?,?\\s*\\w*?:))',each,re.IGNORECASE|re.MULTILINE|re.DOTALL))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating XML file\n",
    "1. Using while loop till the length of the total resumes \n",
    "2. Opening a XML file with write function\n",
    "3. Writing the XML lines into the file using write function\n",
    "4. Splitting the data on the basis of - or . where required \n",
    "5. Replacing the XML unreadable characters like &,<,>\n",
    "6. A XML file is generated as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_special_c(data):\n",
    "    q=str(data).replace(\"&\",\"&amp;\")\n",
    "    w=q.replace(\">\",\"&gt;\")\n",
    "    e=w.replace(\"<\",\"&lt;\")\n",
    "    return(e)           \n",
    "length=len(ids)-1        \n",
    "listing=0\n",
    "xrite=open(\"29554209.xml\",\"w\")\n",
    "xrite.write(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\")\n",
    "while listing <= length-1:\n",
    "    if ids[listing] :\n",
    "        xrite.write(\"<listing id=\\\"\"+ids[listing][0]+\"\\\">\")\n",
    "        xrite.write(\"<title>\")\n",
    "        if title[listing]:\n",
    "            xrite.write(replace_special_c(title[listing][0][1]))\n",
    "        xrite.write(\"</title>\")\n",
    "        xrite.write(\"<location>\")\n",
    "        if location[listing]:\n",
    "            xrite.write(replace_special_c(location[listing]))\n",
    "        xrite.write(\"</location>\")\n",
    "        xrite.write(\"<job_responsibilities>\\n\")\n",
    "        if responsibilty[listing]:\n",
    "            split=responsibilty[listing][0][1].split(\"-\")\n",
    "            for sentence in split:\n",
    "                xrite.write(\"<responsibility>\")\n",
    "                xrite.write(replace_special_c(sentence))\n",
    "                xrite.write(\"</responsibility>\")\n",
    "        xrite.write(\"</job_responsibilities>\")    \n",
    "        xrite.write(\"<job_qualifications>\\n\")\n",
    "        if qualification[listing]:\n",
    "            split=qualification[listing][0][1].split(\"-\")\n",
    "            for sentence in split:\n",
    "                xrite.write(\"<qualification>\")\n",
    "                xrite.write(replace_special_c(sentence))\n",
    "                xrite.write(\"</qualification>\")\n",
    "        xrite.write(\"</job_qualifications>\\n\")  \n",
    "        xrite.write(\"<job_descriptions>\")\n",
    "        if description[listing]:\n",
    "            split=description[listing][0][1].split(\".\")\n",
    "            for sentence in split:\n",
    "                xrite.write(\"<description>\")\n",
    "                xrite.write(replace_special_c(sentence))\n",
    "                xrite.write(\"</description>\")\n",
    "        xrite.write(\"</job_descriptions>\")  \n",
    "        \n",
    "        xrite.write(\"<application_procedure>\")\n",
    "        if procedure[listing]:\n",
    "             xrite.write(replace_special_c(procedure[listing][0][1]))\n",
    "        xrite.write(\"</application_procedure>\") \n",
    "        xrite.write(\"<application_deadline>\")\n",
    "        if dead_line[listing]:\n",
    "             xrite.write(replace_special_c(dead_line[listing][0][1]))\n",
    "        xrite.write(\"</application_deadline>\")\n",
    "        xrite.write(\"<start_date>\")\n",
    "        if start_date[listing]:\n",
    "             xrite.write(replace_special_c(start_date[listing][0][1]))\n",
    "        xrite.write(\"</start_date>\")\n",
    "        xrite.write(\"<about_company>\")\n",
    "        if about_company[listing]:\n",
    "             xrite.write(replace_special_c(about_company[listing][0][1]))\n",
    "        xrite.write(\"</about_company>\")\n",
    "    xrite.write(\"\\n</listing>\")\n",
    "    listing+=1\n",
    "xrite.write(\"\\n</listings>\")        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing JSON file\n",
    "1. Import the json library\n",
    "2. Using for loop for every id in the list\n",
    "3. Write the respective data in each and every respective list\n",
    "4. Simultaniously check if the data is present to avoid indexing error\n",
    "5. Open a json file as write only\n",
    "6. By using the dump function of the json library write the fetched data into the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "count = -1\n",
    "json_code={}\n",
    "for x in ids:\n",
    "    count +=1\n",
    "\n",
    "    # create dic for JSON\n",
    "    json_code[\"id\"] = ids[count][0].strip() if ids[count] else None\n",
    "    json_code[\"sal\"] = salary[count][0][1].strip() if salary[count] else None\n",
    "    json_code[\"title\"] = title[count][0][1].strip() if title[count] else None\n",
    "    json_code[\"loc\"] = location[count][0][1].strip() if location[count] else None\n",
    "    json_code[\"start\"] = start_date[count]\n",
    "    json_code[\"end\"] = dead_line[count][0][1].strip() if dead_line[count] else None\n",
    "    json_code[\"about\"] = about_company[count][0][0].strip() if about_company[count] else None\n",
    "    json_code[\"quali\"] = qualification[count][0][1] if qualification[count] else None\n",
    "    json_code[\"desc\"] = description[count][0][1].strip() if description[count] else None\n",
    "    json_code[\"resp\"] = responsibilty[count][0][1].strip() if responsibilty[count] else None\n",
    "    json_code[\"proc\"] =  procedure[count][0][1].strip() if procedure[count] else None\n",
    "    \n",
    "    with open('29554209.json', 'a') as final:     \n",
    "        json.dump(json_code, final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The output files are 29554209.xml and 29554209.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
